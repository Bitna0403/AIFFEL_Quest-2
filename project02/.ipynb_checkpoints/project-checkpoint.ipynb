{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f101e66c",
   "metadata": {},
   "source": [
    "### üö© Import libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95777bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import visual tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "# import util tools\n",
    "import os\n",
    "from os.path import join    # define route of files\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# import data pre-processing tools\n",
    "import missingno as msno    # check missing data\n",
    "\n",
    "\n",
    "# import ML tools 1\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "# import ML tools 2\n",
    "import sklearn.ensemble as ensemble\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "    # XGBM (extreme GBM), LGBM (lighting GBM) :\n",
    "    # gradient boosting machine (GBM) ÏïåÍ≥†Î¶¨Ï¶ò Í≥ÑÏó¥Ïùò Î≥ÄÌòï\n",
    "    # Í∞ÅÍ∞Å ÎèÖÏûêÏ†ÅÏù∏ Ïò§Ìîà ÏÜåÏä§ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÌòïÌÉúÎ°ú Ìï¥Îãπ Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎã§ :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6b744",
   "metadata": {},
   "source": [
    "### üö© Define constants (hyper params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d58f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2023\n",
    "\n",
    "TEST_SIZE = 0.2    # train/test split ratio for train_test_split()\n",
    "CV_SIZE = 5        # cross validation size\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8585372",
   "metadata": {},
   "source": [
    "### üö© Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a2aafb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>20140527T000000</td>\n",
       "      <td>468000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1160</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>860</td>\n",
       "      <td>300</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6900</td>\n",
       "      <td>-122.292</td>\n",
       "      <td>1330</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15025</th>\n",
       "      <td>15025</td>\n",
       "      <td>20150421T000000</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3410</td>\n",
       "      <td>10125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3410</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5653</td>\n",
       "      <td>-122.223</td>\n",
       "      <td>2290</td>\n",
       "      <td>10125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15026</th>\n",
       "      <td>15026</td>\n",
       "      <td>20140915T000000</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3990</td>\n",
       "      <td>7838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3990</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6857</td>\n",
       "      <td>-122.046</td>\n",
       "      <td>3370</td>\n",
       "      <td>6814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15030</th>\n",
       "      <td>15030</td>\n",
       "      <td>20141014T000000</td>\n",
       "      <td>610685.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98056</td>\n",
       "      <td>47.5137</td>\n",
       "      <td>-122.167</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15031</th>\n",
       "      <td>15031</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>1007500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2600</td>\n",
       "      <td>910</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5537</td>\n",
       "      <td>-122.398</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>15034</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10537 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0          0  20141013T000000   221900.0         3       1.00         1180   \n",
       "1          1  20150225T000000   180000.0         2       1.00          770   \n",
       "3          3  20140627T000000   257500.0         3       2.25         1715   \n",
       "4          4  20150115T000000   291850.0         3       1.50         1060   \n",
       "6          6  20140527T000000   468000.0         2       1.00         1160   \n",
       "...      ...              ...        ...       ...        ...          ...   \n",
       "15025  15025  20150421T000000  1575000.0         4       3.25         3410   \n",
       "15026  15026  20140915T000000   810000.0         4       3.00         3990   \n",
       "15030  15030  20141014T000000   610685.0         4       2.50         2520   \n",
       "15031  15031  20150326T000000  1007500.0         4       3.50         3510   \n",
       "15034  15034  20141015T000000   325000.0         2       0.75         1020   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view  ...  grade  sqft_above  \\\n",
       "0          5650     1.0           0     0  ...      7        1180   \n",
       "1         10000     1.0           0     0  ...      6         770   \n",
       "3          6819     2.0           0     0  ...      7        1715   \n",
       "4          9711     1.0           0     0  ...      7        1060   \n",
       "6          6000     1.0           0     0  ...      7         860   \n",
       "...         ...     ...         ...   ...  ...    ...         ...   \n",
       "15025     10125     2.0           0     0  ...     10        3410   \n",
       "15026      7838     2.0           0     0  ...      9        3990   \n",
       "15030      6023     2.0           0     0  ...      9        2520   \n",
       "15031      7200     2.0           0     0  ...      9        2600   \n",
       "15034      1076     2.0           0     0  ...      7        1020   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0                  0      1955             0    98178  47.5112 -122.257   \n",
       "1                  0      1933             0    98028  47.7379 -122.233   \n",
       "3                  0      1995             0    98003  47.3097 -122.327   \n",
       "4                  0      1963             0    98198  47.4095 -122.315   \n",
       "6                300      1942             0    98115  47.6900 -122.292   \n",
       "...              ...       ...           ...      ...      ...      ...   \n",
       "15025              0      2007             0    98040  47.5653 -122.223   \n",
       "15026              0      2003             0    98053  47.6857 -122.046   \n",
       "15030              0      2014             0    98056  47.5137 -122.167   \n",
       "15031            910      2009             0    98136  47.5537 -122.398   \n",
       "15034              0      2008             0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1340        5650  \n",
       "1               2720        8062  \n",
       "3               2238        6819  \n",
       "4               1650        9711  \n",
       "6               1330        6000  \n",
       "...              ...         ...  \n",
       "15025           2290       10125  \n",
       "15026           3370        6814  \n",
       "15030           2520        6023  \n",
       "15031           2050        6200  \n",
       "15034           1020        1357  \n",
       "\n",
       "[10537 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define routes of data(.csv) files\n",
    "data_dir = \"~/aiffel/kaggle_kakr_housing/data/\"\n",
    "\n",
    "\n",
    "# load csv files -> pd.DataFrame\n",
    "train_data = pd.read_csv(join(data_dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(join(data_dir, \"test.csv\"))\n",
    "\n",
    "\n",
    "train_data = train_data.loc[train_data['id']!=8912]\n",
    "train_data = train_data.loc[train_data['id']!=2302]\n",
    "train_data = train_data.loc[train_data['id']!=4123]\n",
    "\n",
    "#train_data.loc[train_data['sqft_living'] > 13000]\n",
    "train_data.drop(train_data.loc[(train_data['price']>12) & (train_data['grade'] == 3)].index, inplace=True)\n",
    "#train_data.loc[(train_data['price']>12) & (train_data['grade'] == 3)]\n",
    "train_data.drop(train_data.loc[(train_data['price']>14.7) & (train_data['grade'] == 8)].index, inplace=True)\n",
    "#train_data.loc[(train_data['price']>14.7) & (train_data['grade'] == 8)]\n",
    "train_data.drop(train_data.loc[(train_data['price']>15.5) & (train_data['grade'] == 11)].index, inplace=True)\n",
    "#train_data.loc[(train_data['price']>15.5) & (train_data['grade'] == 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cec855",
   "metadata": {},
   "source": [
    "### üö© Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ce60f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train data pre-processing\n",
    "\n",
    "# \"date\" column format change\n",
    "train_data[\"date\"] = train_data[\"date\"].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "# \"price\" column regularization(?) -> grow variation of \"price\" values\n",
    "train_data[\"price\"] = np.log1p(train_data[\"price\"])\n",
    "\n",
    "# \"id\" column remove\n",
    "train_data = train_data.drop(columns = [\"id\"])\n",
    "\n",
    "### test data pre-processing\n",
    "#print(train_data.loc[train_data['sqft_living'] > 13000])\n",
    "\n",
    "# \"date\" column format change\n",
    "test_data[\"date\"] = test_data[\"date\"].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "# \"id\" column remove\n",
    "test_data = test_data.drop(columns = [\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0cc92",
   "metadata": {},
   "source": [
    "### üö© Extract feature matrices (X) & target vectors (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf60e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data -> feature matrix (X) & target vector (y) split\n",
    "X = train_data.drop(columns = [\"price\"])    # exclude target vector column\n",
    "y = train_data[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312d567",
   "metadata": {},
   "source": [
    "### üö© Define useful methods (RMSE, cross validation, grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebed11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSE losses from log(\"price\") values\n",
    "def getRMSE_log2exp(y_test, y_pred):\n",
    "    y_test, y_pred = np.expm1(y_test), np.expm1(y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "\n",
    "# get cross validation scores of \"one\" learning model (for model evaluation)\n",
    "def getCVscore(X, model):\n",
    "    kfold = model_selection.KFold(n_splits = CV_SIZE).get_n_splits(X.values)\n",
    "    score = np.mean(model_selection.cross_val_score(model, X = X.values, y = y, cv = kfold))\n",
    "    print(\"CV score of\", model.__class__.__name__, \":\", score)\n",
    "    return score\n",
    "        \n",
    "    \n",
    "    \n",
    "# search best parameter values for learning models\n",
    "def searchBestParams(model, X, y, param_grid, verbose = 2, n_jobs = 5):\n",
    "    # initialize grid search model\n",
    "    grid = model_selection.GridSearchCV(model, param_grid = param_grid, \\\n",
    "                                        scoring = \"neg_mean_squared_error\", \\\n",
    "                                        cv = CV_SIZE, verbose = verbose, n_jobs = n_jobs)\n",
    "    \n",
    "    # grid search model fitting\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    # return best 5 parameter values\n",
    "    result = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    result[\"score\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    result = result.sort_values(\"score\", ascending = False, ignore_index = True)\n",
    "    print(result.head())\n",
    "    return result.head()\n",
    "\n",
    "\n",
    "\n",
    "# save predicted \"price\" values as a submission file\n",
    "def makeSubmissionFile(y_pred):\n",
    "    data_dir = \"~/aiffel/kaggle_kakr_housing/data/\"\n",
    "    submission = pd.read_csv(join(data_dir, \"sample_submission.csv\"))\n",
    "    submission[\"price\"] = y_pred\n",
    "    submission.to_csv(join(data_dir, \"submission_new.csv\"), index = False)\n",
    "    print(\"The submission file has created succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d999c9b",
   "metadata": {},
   "source": [
    "### üö© Generate & evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58e780aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model instances\n",
    "extreme = xgb.XGBRegressor(random_state = RANDOM_STATE)\n",
    "light = lgb.LGBMRegressor(random_state = RANDOM_STATE)\n",
    "boost = ensemble.GradientBoostingRegressor(random_state = RANDOM_STATE)\n",
    "forest = ensemble.RandomForestRegressor(random_state = RANDOM_STATE)\n",
    "\n",
    "# create my own learning model collections\n",
    "models = [extreme, light, boost, forest]\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model performance (cross validation)\n",
    "#for model in models:\n",
    "#    score = getCVscore(X, model)\n",
    "\n",
    "# Output :\n",
    "# CV score of XGBRegressor  :  0.8973388661281285\n",
    "# CV score of LGBMRegressor  :  0.9024911910917768\n",
    "# CV score of GradientBoostingRegressor  :  0.8796312932769542\n",
    "# CV score of RandomForestRegressor : 0.8851571351312119\n",
    "\n",
    "### It seems four models provide sufficiently high performance!\n",
    "### cross validation Ïã§Ìñâ Í≤∞Í≥º, 4Í∞úÏùò ÌïôÏäµ Î™®Îç∏Ïù¥ Ï∂©Î∂ÑÌïú ÏÑ±Îä•ÏùÑ Ï†úÍ≥µÌïúÎã§Îäî Í≤ÉÏùÑ ÌôïÏù∏\n",
    "### Í∑∏Î†áÎã§Î©¥ Ìï¥Îãπ 4Í∞úÏùò ÌïôÏäµ Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÏó¨ ÌïôÏäµ & ÏòàÏ∏° ÎèÑÏ†Ñ!!\n",
    "### ÏÑ±Îä• ÌôïÏù∏ÏùÑ ÎßàÏ≥§ÏúºÎØÄÎ°ú, ÏÑ±Îä• ÌèâÍ∞Ä Í≥ºÏ†ïÏùÄ Ï£ºÏÑù(#)ÏúºÎ°ú Ï≤òÎ¶¨ÌïòÏó¨ Îã§Ïùå ÏΩîÎìú Ïã§Ìñâ ÎïåÎäî ÏÉùÎûµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756545b",
   "metadata": {},
   "source": [
    "### üö© Search best LGBM param values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6ef20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set available values for LGBM parameters\n",
    "lgbm_param_grid = {\"max_depth\" : [-1], \\\n",
    "                    \"learning_rate\" : [0.01, 0.05, 0.1], \\\n",
    "                    \"n_estimators\" : [50, 75, 100], \\\n",
    "                    \"num_leaves\" : [26, 31, 36], \\\n",
    "                    \"boosting_type\" : [\"gbdt\"], \\\n",
    "                    \"reg_lambda\" : [30, 50, 70]}\n",
    "    # max_depth : ÏùòÏÇ¨ Í≤∞Ï†ï ÎÇòÎ¨¥Ïùò ÍπäÏù¥, Ï†ïÏàò ÏÇ¨Ïö©\n",
    "    # learning_rate : Ìïú Ïä§ÌÖùÏóê Ïù¥ÎèôÌïòÎäî ÏñëÏùÑ Í≤∞Ï†ïÌïòÎäî ÌååÎùºÎØ∏ÌÑ∞, Î≥¥ÌÜµ 0.0001~0.1 ÏÇ¨Ïù¥Ïùò Ïã§Ïàò ÏÇ¨Ïö©\n",
    "    # n_estimators : ÏÇ¨Ïö©ÌïòÎäî Í∞úÎ≥Ñ Î™®Îç∏Ïùò Í∞úÏàò, Î≥¥ÌÜµ 50~100 Ïù¥ÏÉÅÏùò Ï†ïÏàò ÏÇ¨Ïö©\n",
    "    # num_leaves : ÌïòÎÇòÏùò LightGBM Ìä∏Î¶¨Í∞Ä Í∞ÄÏßà Ïàò ÏûàÎäî ÏµúÎåÄ ÏûéÏùò Ïàò\n",
    "    # boosting_type : Î∂ÄÏä§ÌåÖ Î∞©Ïãù, gbdt, rf Îì±Ïùò Î¨∏ÏûêÏó¥ ÏûÖÎ†•\n",
    "    # reg_lambda : L2 regularization term on weights\n",
    "\n",
    "    \n",
    "# Search best set of parameter values\n",
    "#print(searchBestParams(light, X, y, lgbm_param_grid, verbose = 0))\n",
    "\n",
    "# Output :\n",
    "#   boosting_type  learning_rate  max_depth  n_estimators  num_leaves  reg_lambda      score\n",
    "# 0          gbdt            0.1         -1           100          36          30  -0.026989\n",
    "# 1          gbdt            0.1         -1           100          31          30  -0.027051\n",
    "# 2          gbdt            0.1         -1           100          36          50  -0.027284\n",
    "# 3          gbdt            0.1         -1           100          26          30  -0.027552\n",
    "# 4          gbdt            0.1         -1           100          31          50  -0.027646\n",
    "\n",
    "### LGBMÎäî learning_rate = 0.1, n_estimators = 100, num_leaves = 36, reg_lambda = 30 Ïùº Îïå ÏµúÏÉÅÏùò ÏÑ±Îä•ÏûÑÏùÑ ÌôïÏù∏\n",
    "### XGBM ÎòêÌïú LGBMÍ≥º Ïú†ÏÇ¨Ìïú GBM Í≥ÑÏó¥Ïùò ÌïôÏäµ ÏïåÍ≥†Î¶¨Ï¶òÏù¥ÎØÄÎ°ú, Ïú†ÏÇ¨Ìïú ÏàòÏπò ÎåÄÏûÖÌïòÎ©¥ OK\n",
    "### ÌååÎùºÎØ∏ÌÑ∞ Í∞íÎ≥Ñ ÏÑ±Îä• ÌôïÏù∏ÏùÑ ÎßàÏ≥§ÏúºÎØÄÎ°ú, ÌååÎùºÎØ∏ÌÑ∞ ÌÉêÏÉâ Í≥ºÏ†ïÏùÄ Ï£ºÏÑù(#)ÏúºÎ°ú Ï≤òÎ¶¨ÌïòÏó¨ Îã§Ïùå ÏΩîÎìú Ïã§Ìñâ ÎïåÎäî ÏÉùÎûµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa6e60",
   "metadata": {},
   "source": [
    "### üö© Adjust XGBD & LGBD params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d84dfa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate another model instances with adjusted params\n",
    "extreme = xgb.XGBRegressor(random_state = RANDOM_STATE, learning_rate = 0.2, n_estimators = 100)\n",
    "light = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "\n",
    "# Update XGBD & LGBD models in my model collection\n",
    "models[0] = extreme\n",
    "models[1] = light\n",
    "\n",
    "### grid search Í≤∞Í≥º Í∞íÍ≥º Ïú†ÏÇ¨Ìïú Í∞í ÏúÑÏ£ºÎ°ú Îã§ÏñëÌïú Í∞íÏùÑ ÏãúÎèÑÌï¥ Î≥∏ Í≤∞Í≥º, Ìï¥Îãπ ÌååÎùºÎØ∏ÌÑ∞ Í∞íÏúºÎ°ú Í≤∞Ï†ï"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca8f0",
   "metadata": {},
   "source": [
    "### üö© Perform fit() & predict() -> Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "571e3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for model in models :\n",
    "    # split train data -> for training & for valication\n",
    "    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, \\\n",
    "                                        test_size = TEST_SIZE, random_state = RANDOM_STATE)\n",
    "\n",
    "    # model fitting (learning)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict \"price\"\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    # get error (wish less than 1.1M)\n",
    "    error = getRMSE_log2exp(y_valid, y_pred)\n",
    "    print(\"RMSE of\", model.__class__.__name__, \" : \", error)\n",
    "\"\"\"\n",
    "print('test')\n",
    "    \n",
    "# Output :\n",
    "# RMSE of XGBRegressor  :  107509.3104391456\n",
    "# RMSE of LGBMRegressor  :  104654.07159199048\n",
    "# RMSE of GradientBoostingRegressor  :  128360.19649691365\n",
    "# RMSE of RandomForestRegressor  :  125487.07102453562\n",
    "\n",
    "### XGBM, LGBM Î™®Îç∏Ïù¥ Ìù¨ÎßùÏù¥ Î≥¥Ïù¥ÎØÄÎ°ú Îëê Í∞ÄÏßÄ Î™®Îç∏Ïóê ÎåÄÌïòÏó¨ ensemble Í∏∞Î≤ïÏùÑ ÏãúÎèÑÌï¥Î≥¥Ïûê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6eab1e",
   "metadata": {},
   "source": [
    "### üö© Define ensemble system methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ba87889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create XGBM/LGBM models with random seed and fitting for EPOCHS iteration\n",
    "def getAveragingBlending(X, y, X_test, epochs, XGBM = False, LGBM = False):\n",
    "    y_preds = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if XGBM:    # XGBM model\n",
    "            model = xgb.XGBRegressor(learning_rate = 0.2, n_estimators = 100)\n",
    "        else:      # LGBM model\n",
    "            model = lgb.LGBMRegressor(learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "            \n",
    "        X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size = TEST_SIZE)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_preds.append(y_pred)  # save predicted values from each model\n",
    "\n",
    "    y_preds = np.array(y_preds) \n",
    "    mean = np.mean(y_preds, axis = 0)    # get mean values of predicted values\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4740c",
   "metadata": {},
   "source": [
    "### üö© Predict \"price\" with various learning ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53717ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. predict with only one XGBM\n",
    "#extreme = xgb.XGBRegressor(random_state = RANDOM_STATE, learning_rate = 0.2, n_estimators = 100)\n",
    "#extreme.fit(X, y)\n",
    "#y_pred = extreme.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-1. predict with only one LGBM\n",
    "#light = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36)\n",
    "#light.fit(X, y)\n",
    "#y_pred = light.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-2. predict with only one LGBM & regularization parameter 30\n",
    "#light_reg = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "#light_reg.fit(X, y)\n",
    "#y_pred = light_reg.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-3. predict with only one LGBM & regularization parameter 50\n",
    "light_reg = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, max_depth = -1, n_estimators = 300, num_leaves = 36, reg_lambda = 50)\n",
    "light_reg.fit(X, y)\n",
    "y_pred = light_reg.predict(test_data)\n",
    "\n",
    "\n",
    "# 3. predict with ensembled XGBMs\n",
    "#y_pred = getAveragingBlending(X, y, test_data, EPOCHS, XGBM = True)\n",
    "\n",
    "\n",
    "# 4. predict with ensembled LGBMs\n",
    "#y_pred = getAveragingBlending(X_train, y_train, X_valid, EPOCHS, LGBM = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ac8ce",
   "metadata": {},
   "source": [
    "### üö© Save predicted \"price\" as submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "214748d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission file has created succesfully.\n"
     ]
    }
   ],
   "source": [
    "# recover original price value range\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "# save as file\n",
    "makeSubmissionFile(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6587d",
   "metadata": {},
   "source": [
    "-----\n",
    "**ÌöåÍ≥†Î°ù** :  \n",
    "XGBM, LGBM Ïù¥ Îã§Î•∏ ÌïôÏäµ Î™®Îç∏Ïóê ÎπÑÌï¥ ÏÑ±Îä•Ïù¥ Ï¢ãÎã§ÎçòÎç∞, Î™∏ÏÜå Ï≤¥ÌóòÌï† Ïàò ÏûàÏóàÎã§  \n",
    "ÎòêÌïú Í∞ôÏùÄ Î™®Îç∏Ïù¥ÎùºÎèÑ parameter Í∞íÏóê Îî∞ÎùºÏÑúÎèÑ Ï∂©Î∂ÑÌûà ÏÑ±Îä•ÏùÑ Ï°∞Ï†ïÌï† Ïàò ÏûàÏùåÏùÑ Ï≤¥Í∞êÌñàÎã§  \n",
    "ÎèôÏùºÌïú Î™®Îç∏Ïóê ÏÑúÎ°ú Îã§Î•∏ random seedÎ•º Î∂ÄÏó¨Ìï¥ÏÑú ensemble ÏùÑ ÏãúÎèÑÌïòÏòÄÎäîÎç∞, ÎåÄÎ∂ÄÎ∂Ñ ÏÑ±Îä•Ïù¥ Ï¢ãÏßÄ ÏïäÏïòÎã§\n",
    "ÏÑúÎ°ú Îã§Î•∏ Î™®Îç∏Îì§ÏùÑ Î¨∂Ïñ¥ÏÑú ensemble ÏùÑ Ìï¥Ïïº ÏÑ±Îä•Ïù¥ Ìñ•ÏÉÅÎêòÎäîÍ±∏Íπå?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47121b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
